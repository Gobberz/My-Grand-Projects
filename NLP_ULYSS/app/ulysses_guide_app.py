import streamlit as st
import pandas as pd
from analysis_functions import * # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –í–°–ï –∏–∑ –Ω–∞—à–µ–π —á–∏—Å—Ç–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∞—Ç—å —ç—Ç–æ –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∫–ª–∏–∫–µ
@st.cache_resource
def load_models():
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")
    download_nltk_data()
    nlp_model = load_spacy_model()
    print("–ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
    return nlp_model

nlp = load_models()

st.set_page_config(page_title="Ulysses Guide", layout="wide")
st.title("üìö Ulysses NLP Guide")
st.markdown("*–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è ¬´–£–ª–∏—Å—Å–∞¬ª —Å –ø–æ–º–æ—â—å—é NLP*")

analysis_type = st.sidebar.selectbox(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞:",
    ["–ê–Ω–∞–ª–∏–∑ –ø–æ—Ç–æ–∫–∞ —Å–æ–∑–Ω–∞–Ω–∏—è", "–ì–µ–æ-–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω–æ–µ –∫–∞—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"]
)

user_text = st.text_area(
    "–í–≤–µ–¥–∏—Ç–µ –æ—Ç—Ä—ã–≤–æ–∫ –∏–∑ ¬´–£–ª–∏—Å—Å–∞¬ª:",
    height=250,
    value="""Stately, plump Buck Mulligan came from the stairhead, bearing a bowl of lather on which a mirror and a razor lay crossed.
‚ÄîIntroibo ad altare Dei.
Halted, he peered down the dark winding stairs and called out coarsely:
‚ÄîCome up, Kinch! Come up, you fearful jesuit!"""
)

if st.button("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å", type="primary"):
    if user_text.strip():
        with st.spinner("–ê–Ω–∞–ª–∏–∑..."):
            if analysis_type == "–ê–Ω–∞–ª–∏–∑ –ø–æ—Ç–æ–∫–∞ —Å–æ–∑–Ω–∞–Ω–∏—è":
                st.subheader("üß† –ê–Ω–∞–ª–∏–∑ –ø–æ—Ç–æ–∫–∞ —Å–æ–∑–Ω–∞–Ω–∏—è")
                segments = segment_text_by_character(user_text, ["Stephen", "Buck Mulligan"])
                sentiment = analyze_sentiment_over_time(segments)
                st.dataframe(pd.DataFrame(sentiment).T.reset_index().rename(columns={'index': '–ü–µ—Ä—Å–æ–Ω–∞–∂'}))

            elif analysis_type == "–ì–µ–æ-–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω–æ–µ –∫–∞—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ":
                st.subheader("üó∫Ô∏è –ì–µ–æ-–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω–∞—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è")
                locations = extract_locations_ner(user_text, nlp)
                if locations:
                    st.write("**–ù–∞–π–¥–µ–Ω–Ω—ã–µ –ª–æ–∫–∞—Ü–∏–∏:**", ", ".join(locations))
                    # –í –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–ª–≥–∏–º, –ø–æ—ç—Ç–æ–º—É –ø–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –≤—ã–≤–æ–¥–∏–º
                    st.info("–í Jupyter-–Ω–æ—É—Ç–±—É–∫–µ —ç—Ç–∏ –ª–æ–∫–∞—Ü–∏–∏ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –Ω–∞ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π –∫–∞—Ä—Ç–µ.")
                else:
                    st.write("–õ–æ–∫–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —ç—Ç–æ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ.")
    else:
        st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")